{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOSmfgAO/KMVdp9X33SxGpY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ResNetを使った画像認識を体験してみよう！"],"metadata":{"id":"bXv2YcTXp7uB"}},{"cell_type":"markdown","source":["**torchライブラリのインポート**  \n","※Pytorchはディープラーニングを簡単に使用するためのフレームワークであり、torchはPytorchの中のライブラリの一つ"],"metadata":{"id":"SQOWtuKnDo58"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9N89mBkaDnpH","executionInfo":{"status":"ok","timestamp":1703321281050,"user_tz":-540,"elapsed":4129,"user":{"displayName":"ねるねるねる寝","userId":"01795394523446041521"}},"outputId":"72ed51c4-dc71-47b2-fb2a-46f08a9d2f14"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.1.0+cu121\n"]}],"source":["import torch\n","print(torch.__version__)"]},{"cell_type":"code","source":["torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_LSUhjvQE_QL","executionInfo":{"status":"ok","timestamp":1703257954574,"user_tz":-540,"elapsed":268,"user":{"displayName":"ねるねるねる寝","userId":"01795394523446041521"}},"outputId":"c18c096c-5ff3-4e0d-f62d-2b5d2e57663d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["**訓練済みモデルの表示**    \n","* 大文字で表示されたものは利用可能なモデルのPythonクラス\n","* 小文字で表示されたものは大文字で表示されたクラスのインスタンス化されたモデルを返す関数や事前訓練済みのモデルをロードするためのメソッド"],"metadata":{"id":"LxupKCS7Fmos"}},{"cell_type":"code","source":["from torchvision import models\n","dir(models)"],"metadata":{"id":"LOgJnDv-F8sp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**AlexNetオブジェクトの呼び出し**  \n","※この時点ではパラメータ変数が訓練されていない初期状態"],"metadata":{"id":"Ar2gqfzILIwp"}},{"cell_type":"code","source":["alexnet = models.AlexNet()"],"metadata":{"id":"By6UMRTUGIEc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**訓練済みのResNetオブジェクトの呼び出し**  \n","※ここでは101層の畳み込みニューラルネットワークを使用"],"metadata":{"id":"lnA-7dUtLroN"}},{"cell_type":"code","source":["resnet = models.resnet101(pretrained=True)"],"metadata":{"id":"qFkz5uyFLrJv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**ResNet101の中身を確認**  \n","ここでは一行が一つのモジュール(Pytorchにおける)を表している  \n","* Pythonのモジュールはコードの組織化や再利用のためのファイル単位の概念  \n","* PyTorchのモジュールはニューラルネットワークの構成要素を定義するためのクラスベースの概念"],"metadata":{"id":"83PLK3BFQLTk"}},{"cell_type":"code","source":["resnet"],"metadata":{"id":"p-eaXrO3Oy8W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**入力画像の前処理関数を定義**\n","\n","\n","1.   256 × 256のサイズに変換\n","2.   画像の中央を224 × 224のサイズで切り取り\n","3.   tensorに変換(色、高さ、幅の３次元配列)\n","4.   設定した平均値と標準偏差で標準化\n","\n","**正規化と標準化**  \n","お互い特徴量の単位が違っていたりしたときに、各次元の関係をわかりやすくするために使われる。ニューラルネットワークの学習が安定する。画像処理においては、照明の違いや露出の違いなどによる影響を減少させることができる。過学習を防ぎ、汎化性能を向上させることに役立つ\n","* 正規化: データの最小値を0、最大値を1の範囲に収める\n","    * 外れ値の影響を受けやすい\n","    * 最大値と最小値がわかっている時に使われる\n","\n","* 標準化: 平均を0, 標準偏差を1とする\n","\n","※transforms.Compose は、PyTorchの torchvision ライブラリの一部であり、主に画像処理のための複数のトランスフォーム（変換）を組み合わせるために使用されます。これは、機械学習モデルのデータ前処理やデータ拡張のステップに非常に役立ちます。"],"metadata":{"id":"9Q4RxlCVSHfz"}},{"cell_type":"code","source":["from torchvision import transforms\n","\n","preprocess = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    )])\n","# print(type(preprocess))"],"metadata":{"id":"_fObGYs5SLPS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703321675962,"user_tz":-540,"elapsed":364,"user":{"displayName":"ねるねるねる寝","userId":"01795394523446041521"}},"outputId":"fdbb5ef5-3c38-445e-88a5-a36acaab52c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torchvision.transforms.transforms.Compose'>\n"]}]},{"cell_type":"markdown","source":["**マウント**"],"metadata":{"id":"N6uUyIX2eFrh"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Idx8zaO1eJKY","executionInfo":{"status":"ok","timestamp":1703264465567,"user_tz":-540,"elapsed":17833,"user":{"displayName":"ねるねるねる寝","userId":"01795394523446041521"}},"outputId":"b2891344-d928-442a-bce1-9df40e32f35c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["**テスト画像を読み込み・表示**"],"metadata":{"id":"qql9PFU5dM28"}},{"cell_type":"code","source":["from PIL import Image\n","import numpy as np\n","\n","img = Image.open('/content/drive/MyDrive/Colab Notebooks/bobby.jpg')\n","# n = np.array(img)\n","# print(n)\n","# print(n.shape)\n","img"],"metadata":{"id":"RjVxAbdndbX7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**読み込んだ画像を用意しておいた前処理用の関数に通す**"],"metadata":{"id":"HEcpRs_lft86"}},{"cell_type":"code","source":["img_t = preprocess(img)\n","print(img_t)\n","print(type(img_t))"],"metadata":{"id":"BMdSG8_yf29W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**第1次元に次元を追加**"],"metadata":{"id":"sTyiwM7bhhCF"}},{"cell_type":"code","source":["batch_t = torch.unsqueeze(img_t, 0)"],"metadata":{"id":"V7ArNKnohva5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**推論を行うためにネットワークをevalに変更**"],"metadata":{"id":"BqvW9hZfjHao"}},{"cell_type":"code","source":["resnet.eval()"],"metadata":{"id":"n4sxSEMijS-V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**ImageNetの各クラスに対応するスコアベクトルを計算**"],"metadata":{"id":"W3k_W-juj7U-"}},{"cell_type":"code","source":["out = resnet(batch_t)\n","print(out)\n","print(type(out))\n","print(out.shape)"],"metadata":{"id":"LJW06cYYkTvt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**ラベルをリストアップしたファイルを読み込み**"],"metadata":{"id":"uMBtBQbklPAk"}},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Colab Notebooks/imagenet_classes.txt') as f:\n","  labels = [label.strip() for label in f.readlines()]\n","print(labels)"],"metadata":{"id":"FExOSZjbkaqw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ラベルごとのスコアの最大値とそのインデックスを取得"],"metadata":{"id":"i6A7zlRhmlrA"}},{"cell_type":"code","source":["val, index = torch.max(out, 1)\n","print(val)\n","print(index)"],"metadata":{"id":"-JKwREnAmxYa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**最もスコアの高かったラベルとその予測に対する信頼度を表示**"],"metadata":{"id":"rBlODEkmnzvP"}},{"cell_type":"code","source":["percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n","labels[index[0]], percentage[index[0]].item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4WZu39Mn8zG","executionInfo":{"status":"ok","timestamp":1703267080755,"user_tz":-540,"elapsed":249,"user":{"displayName":"ねるねるねる寝","userId":"01795394523446041521"}},"outputId":"cd7c27cc-5800-4e98-a2a6-3c7782779189"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('golden retriever', 96.57185363769531)"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["**スコアの高かったラベルとその予測に対する信頼度を上から５つ表示**"],"metadata":{"id":"xpJ5V2cqoWiF"}},{"cell_type":"code","source":["_, indices = torch.sort(out, descending=True)\n","[(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lO2XTC5VoRbg","executionInfo":{"status":"ok","timestamp":1703267321568,"user_tz":-540,"elapsed":322,"user":{"displayName":"ねるねるねる寝","userId":"01795394523446041521"}},"outputId":"4237285e-7ef5-4549-b3b8-9cfffcc4cc06"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('golden retriever', 96.57185363769531),\n"," ('Labrador retriever', 2.6082630157470703),\n"," ('cocker spaniel, English cocker spaniel, cocker', 0.26996269822120667),\n"," ('redbone', 0.17958903312683105),\n"," ('tennis ball', 0.10991978645324707)]"]},"metadata":{},"execution_count":47}]}]}